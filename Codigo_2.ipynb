{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5dc8203",
   "metadata": {},
   "source": [
    "## Codigo de practica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0cb49b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (111805284.py, line 47)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfor page in link\u001b[39m\n                    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected ':'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#third party advice\n",
    "\n",
    "# 1. Obtener la URL\n",
    "url = \"https://books.toscrape.com/\"\n",
    "respuesta_obtenida = requests.get(url)\n",
    "html_obtenido = respuesta_obtenida.text  # HTML como string\n",
    "\n",
    "# 2. Parsear ese HTML con BeautifulSoup\n",
    "soup = BeautifulSoup(html_obtenido, 'html.parser')  \n",
    "\n",
    "#categorias\n",
    "\n",
    "# # --- MÃ©todo 1: usando ul_menu y for ---\n",
    "# categorias = soup.find('ul', class_='nav nav-list')\n",
    "# items = categorias.find_all('li')\n",
    "\n",
    "# diccionario_links = {}\n",
    "\n",
    "# for li in items:\n",
    "#     enlace = li.find('a')\n",
    "#     texto = enlace.text.strip()\n",
    "#     link = enlace['href']\n",
    "#     diccionario_links[texto] = link\n",
    "    \n",
    "# print('MÃ©todo 1:', diccionario_links)\n",
    "\n",
    "# # --- MÃ©todo 2: usando comprensiÃ³n de diccionario y select ---\n",
    "# diccionario_links2 = {a.text.strip(): a['href'] for a in soup.select('ul.nav.nav-list li a')}\n",
    "# print('MÃ©todo 2:', diccionario_links2)\n",
    "\n",
    "# --- MÃ©todo 3: usando un bucle for y select, pero en menos lÃ­neas ---\n",
    "\n",
    "diccionario_links3 = {}\n",
    "for a in soup.select('ul.nav.nav-list li a'):\n",
    "    diccionario_links3[a.text.strip()] = url + a['href']\n",
    "print(diccionario_links3)\n",
    "\n",
    "\n",
    "for link in diccionario_links3.keys():\n",
    "    link = requests.get(url)\n",
    "    link_text = link.text\n",
    "    if link_text.find('ul', class_ = 'pager') == True:\n",
    "        for page in link\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f3bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ PÃ¡gina 1 -> 20 libros encontrados\n",
      "ğŸ“š A Light in the Attic | ğŸ’µ Ã‚Â£51.77 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\n",
      "ğŸ“š Tipping the Velvet | ğŸ’µ Ã‚Â£53.74 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html\n",
      "ğŸ“š Soumission | ğŸ’µ Ã‚Â£50.10 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/soumission_998/index.html\n",
      "ğŸ“š Sharp Objects | ğŸ’µ Ã‚Â£47.82 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/sharp-objects_997/index.html\n",
      "ğŸ“š Sapiens: A Brief History of Humankind | ğŸ’µ Ã‚Â£54.23 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html\n",
      "ğŸ“š The Requiem Red | ğŸ’µ Ã‚Â£22.65 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/the-requiem-red_995/index.html\n",
      "ğŸ“š The Dirty Little Secrets of Getting Your Dream Job | ğŸ’µ Ã‚Â£33.34 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "ğŸ“š The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull | ğŸ’µ Ã‚Â£17.93 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "ğŸ“š The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics | ğŸ’µ Ã‚Â£22.60 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "ğŸ“š The Black Maria | ğŸ’µ Ã‚Â£52.15 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/the-black-maria_991/index.html\n",
      "ğŸ“š Starving Hearts (Triangular Trade Trilogy, #1) | ğŸ’µ Ã‚Â£13.99 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "ğŸ“š Shakespeare's Sonnets | ğŸ’µ Ã‚Â£20.66 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/shakespeares-sonnets_989/index.html\n",
      "ğŸ“š Set Me Free | ğŸ’µ Ã‚Â£17.46 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/set-me-free_988/index.html\n",
      "ğŸ“š Scott Pilgrim's Precious Little Life (Scott Pilgrim #1) | ğŸ’µ Ã‚Â£52.29 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "ğŸ“š Rip it Up and Start Again | ğŸ’µ Ã‚Â£35.02 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/rip-it-up-and-start-again_986/index.html\n",
      "ğŸ“š Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991 | ğŸ’µ Ã‚Â£57.25 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "ğŸ“š Olio | ğŸ’µ Ã‚Â£23.88 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/olio_984/index.html\n",
      "ğŸ“š Mesaerion: The Best Science Fiction Stories 1800-1849 | ğŸ’µ Ã‚Â£37.59 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "ğŸ“š Libertarianism for Beginners | ğŸ’µ Ã‚Â£51.33 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/libertarianism-for-beginners_982/index.html\n",
      "ğŸ“š It's Only the Himalayas | ğŸ’µ Ã‚Â£45.17 | ğŸ“¦ In stock | ğŸ”— https://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html\n",
      "ğŸ“š It's Only the Himalayas | ğŸ’µ Ã‚Â£45.17 | ğŸ“¦ In stock | ğŸ“‚ Travel\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "libros = None\n",
    "\n",
    "\n",
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "\n",
    "#funcion para recorrer todas las paginas \n",
    "\n",
    "for page in range(1, 2):  # Hay 50 pÃ¡ginas en total\n",
    "    url = base_url.format(page)\n",
    "    respuesta = requests.get(url)\n",
    "    soup = BeautifulSoup(respuesta.text, 'html.parser')\n",
    "\n",
    "    # AquÃ­ haces scraping de los libros de esa pÃ¡gina\n",
    "    libros = soup.find_all('article', class_='product_pod')\n",
    "    print(f\"ğŸ“„ PÃ¡gina {page} -> {len(libros)} libros encontrados\")\n",
    "\n",
    "# recorrer_paginas()\n",
    "\n",
    "\n",
    "#   \n",
    "\n",
    "for libro in libros:\n",
    "    titulo = libro.h3.a['title']\n",
    "    precio = libro.find('p', class_='price_color').text\n",
    "    disponibilidad = libro.find('p', class_='instock availability').text.strip()\n",
    "\n",
    "    # Enlace al detalle del libro (relativo -> convertir a absoluto)\n",
    "    enlace_relativo = libro.h3.a['href']\n",
    "    enlace_absoluto = \"https://books.toscrape.com/catalogue/\" + enlace_relativo\n",
    "\n",
    "    print(f\"ğŸ“š {titulo} | ğŸ’µ {precio} | ğŸ“¦ {disponibilidad} | ğŸ”— {enlace_absoluto}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "detalle = requests.get(enlace_absoluto)\n",
    "soup_detalle = BeautifulSoup(detalle.text, 'html.parser')\n",
    "\n",
    "# CategorÃ­a: estÃ¡ en un breadcrumb (<ul class=\"breadcrumb\">)\n",
    "categoria = soup_detalle.find('ul', class_='breadcrumb').find_all('a')[-1].text\n",
    "\n",
    "print(f\"ğŸ“š {titulo} | ğŸ’µ {precio} | ğŸ“¦ {disponibilidad} | ğŸ“‚ {categoria}\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f384c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c55ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategorÃ­as encontradas: 50\n",
      "{'Travel': 'https://books.toscrape.com/catalogue/category/books/travel_2/index.html', 'Mystery': 'https://books.toscrape.com/catalogue/category/books/mystery_3/index.html', 'Historical Fiction': 'https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html', 'Sequential Art': 'https://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html', 'Classics': 'https://books.toscrape.com/catalogue/category/books/classics_6/index.html', 'Philosophy': 'https://books.toscrape.com/catalogue/category/books/philosophy_7/index.html', 'Romance': 'https://books.toscrape.com/catalogue/category/books/romance_8/index.html', 'Womens Fiction': 'https://books.toscrape.com/catalogue/category/books/womens-fiction_9/index.html', 'Fiction': 'https://books.toscrape.com/catalogue/category/books/fiction_10/index.html', 'Childrens': 'https://books.toscrape.com/catalogue/category/books/childrens_11/index.html', 'Religion': 'https://books.toscrape.com/catalogue/category/books/religion_12/index.html', 'Nonfiction': 'https://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html', 'Music': 'https://books.toscrape.com/catalogue/category/books/music_14/index.html', 'Default': 'https://books.toscrape.com/catalogue/category/books/default_15/index.html', 'Science Fiction': 'https://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html', 'Sports and Games': 'https://books.toscrape.com/catalogue/category/books/sports-and-games_17/index.html', 'Add a comment': 'https://books.toscrape.com/catalogue/category/books/add-a-comment_18/index.html', 'Fantasy': 'https://books.toscrape.com/catalogue/category/books/fantasy_19/index.html', 'New Adult': 'https://books.toscrape.com/catalogue/category/books/new-adult_20/index.html', 'Young Adult': 'https://books.toscrape.com/catalogue/category/books/young-adult_21/index.html', 'Science': 'https://books.toscrape.com/catalogue/category/books/science_22/index.html', 'Poetry': 'https://books.toscrape.com/catalogue/category/books/poetry_23/index.html', 'Paranormal': 'https://books.toscrape.com/catalogue/category/books/paranormal_24/index.html', 'Art': 'https://books.toscrape.com/catalogue/category/books/art_25/index.html', 'Psychology': 'https://books.toscrape.com/catalogue/category/books/psychology_26/index.html', 'Autobiography': 'https://books.toscrape.com/catalogue/category/books/autobiography_27/index.html', 'Parenting': 'https://books.toscrape.com/catalogue/category/books/parenting_28/index.html', 'Adult Fiction': 'https://books.toscrape.com/catalogue/category/books/adult-fiction_29/index.html', 'Humor': 'https://books.toscrape.com/catalogue/category/books/humor_30/index.html', 'Horror': 'https://books.toscrape.com/catalogue/category/books/horror_31/index.html', 'History': 'https://books.toscrape.com/catalogue/category/books/history_32/index.html', 'Food and Drink': 'https://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html', 'Christian Fiction': 'https://books.toscrape.com/catalogue/category/books/christian-fiction_34/index.html', 'Business': 'https://books.toscrape.com/catalogue/category/books/business_35/index.html', 'Biography': 'https://books.toscrape.com/catalogue/category/books/biography_36/index.html', 'Thriller': 'https://books.toscrape.com/catalogue/category/books/thriller_37/index.html', 'Contemporary': 'https://books.toscrape.com/catalogue/category/books/contemporary_38/index.html', 'Spirituality': 'https://books.toscrape.com/catalogue/category/books/spirituality_39/index.html', 'Academic': 'https://books.toscrape.com/catalogue/category/books/academic_40/index.html', 'Self Help': 'https://books.toscrape.com/catalogue/category/books/self-help_41/index.html', 'Historical': 'https://books.toscrape.com/catalogue/category/books/historical_42/index.html', 'Christian': 'https://books.toscrape.com/catalogue/category/books/christian_43/index.html', 'Suspense': 'https://books.toscrape.com/catalogue/category/books/suspense_44/index.html', 'Short Stories': 'https://books.toscrape.com/catalogue/category/books/short-stories_45/index.html', 'Novels': 'https://books.toscrape.com/catalogue/category/books/novels_46/index.html', 'Health': 'https://books.toscrape.com/catalogue/category/books/health_47/index.html', 'Politics': 'https://books.toscrape.com/catalogue/category/books/politics_48/index.html', 'Cultural': 'https://books.toscrape.com/catalogue/category/books/cultural_49/index.html', 'Erotica': 'https://books.toscrape.com/catalogue/category/books/erotica_50/index.html', 'Crime': 'https://books.toscrape.com/catalogue/category/books/crime_51/index.html'}\n",
      "1 {'TÃ­tulo': '1,000 Places to See Before You Die', 'Autores': ['Patricia Schultz'], 'Precio': 'Ã‚Â£26.08', 'Disponibilidad': 'In stock', 'Rating': 'Five', 'CategorÃ­a': 'Travel', 'Stock': 'In stock (1 available)', 'URL': 'https://books.toscrape.com/catalogue/1000-places-to-see-before-you-die_1/index.html'}\n",
      "2 {'TÃ­tulo': 'Delivering the Truth (Quaker Midwife Mystery #1)', 'Autores': ['Edith Maxwell'], 'Precio': 'Ã‚Â£20.89', 'Disponibilidad': 'In stock', 'Rating': 'Four', 'CategorÃ­a': 'Mystery', 'Stock': 'In stock (7 available)', 'URL': 'https://books.toscrape.com/catalogue/delivering-the-truth-quaker-midwife-mystery-1_464/index.html'}\n",
      "3 {'TÃ­tulo': \"1st to Die (Women's Murder Club #1)\", 'Autores': [], 'Precio': 'Ã‚Â£53.98', 'Disponibilidad': 'In stock', 'Rating': 'One', 'CategorÃ­a': 'Mystery', 'Stock': 'In stock (1 available)', 'URL': 'https://books.toscrape.com/catalogue/1st-to-die-womens-murder-club-1_2/index.html'}\n",
      "4 {'TÃ­tulo': 'Girl in the Blue Coat', 'Autores': [], 'Precio': 'Ã‚Â£46.83', 'Disponibilidad': 'In stock', 'Rating': 'Two', 'CategorÃ­a': 'Historical Fiction', 'Stock': 'In stock (3 available)', 'URL': 'https://books.toscrape.com/catalogue/girl-in-the-blue-coat_160/index.html'}\n",
      "5 {'TÃ­tulo': \"A Spy's Devotion (The Regency Spies of London #1)\", 'Autores': [], 'Precio': 'Ã‚Â£16.97', 'Disponibilidad': 'In stock', 'Rating': 'Five', 'CategorÃ­a': 'Historical Fiction', 'Stock': 'In stock (1 available)', 'URL': 'https://books.toscrape.com/catalogue/a-spys-devotion-the-regency-spies-of-london-1_3/index.html'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     82\u001b[39m     enlace_abs = enlace_rel\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Hacemos una peticiÃ³n GET al detalle del libro para obtener mÃ¡s informaciÃ³n\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m detalle = \u001b[43mget_with_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[43menlace_abs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m detalle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mget_with_retries\u001b[39m\u001b[34m(url, headers, max_retries, timeout)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries):\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     11\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mIntento \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fallido para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gatoh\\Documents\\CODE PRO\\The Huddle\\4-SQL-webscraping\\venv\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gatoh\\Documents\\CODE PRO\\The Huddle\\4-SQL-webscraping\\venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gatoh\\Documents\\CODE PRO\\The Huddle\\4-SQL-webscraping\\venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gatoh\\Documents\\CODE PRO\\The Huddle\\4-SQL-webscraping\\venv\\Lib\\site-packages\\requests\\sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gatoh\\Documents\\CODE PRO\\The Huddle\\4-SQL-webscraping\\venv\\Lib\\site-packages\\requests\\models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gatoh\\Documents\\CODE PRO\\The Huddle\\4-SQL-webscraping\\venv\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gatoh\\Documents\\CODE PRO\\The Huddle\\4-SQL-webscraping\\venv\\Lib\\site-packages\\urllib3\\response.py:1091\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1094\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gatoh\\Documents\\CODE PRO\\The Huddle\\4-SQL-webscraping\\venv\\Lib\\site-packages\\urllib3\\response.py:980\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    978\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gatoh\\Documents\\CODE PRO\\The Huddle\\4-SQL-webscraping\\venv\\Lib\\site-packages\\urllib3\\response.py:904\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    901\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    906\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gatoh\\Documents\\CODE PRO\\The Huddle\\4-SQL-webscraping\\venv\\Lib\\site-packages\\urllib3\\response.py:887\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# import csv\n",
    "import time\n",
    "\n",
    "def get_with_retries(url, headers=None, max_retries=3, timeout=5):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return requests.get(url, headers=headers, timeout=timeout)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f'Intento {attempt+1} fallido para {url}: {e}')\n",
    "            time.sleep(2)\n",
    "    print(f'No se pudo acceder a {url} despuÃ©s de {max_retries} intentos.')\n",
    "    return None\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "\n",
    "# Definimos la URL base del sitio web a scrapear\n",
    "url = \"https://books.toscrape.com/\"\n",
    "\n",
    "# Hacemos una peticiÃ³n GET a la pÃ¡gina principal para obtener el HTML\n",
    "respuesta = get_with_retries(url, headers=headers, timeout=1)\n",
    "if respuesta is None:\n",
    "    raise Exception('No se pudo obtener la pÃ¡gina principal')\n",
    "soup = BeautifulSoup(respuesta.text, 'html.parser')\n",
    "\n",
    "# Obtenemos todas las categorÃ­as disponibles (excepto 'All books') y armamos un diccionario con el nombre y el link absoluto\n",
    "categorias = {\n",
    "    a.text.strip(): url + a['href'] \n",
    "    for a in soup.select('ul.nav.nav-list li a') \n",
    "    if a['href'] != 'catalogue/category/books_1/index.html'\n",
    "}  # Excluye 'All books' de la lista de categorÃ­as\n",
    "\n",
    "print(f\"CategorÃ­as encontradas: {len(categorias)}\")\n",
    "print(categorias)\n",
    "\n",
    "# Creamos una lista vacÃ­a donde guardaremos la informaciÃ³n de todos los libros\n",
    "libros_data = []\n",
    "contador = 0\n",
    "# Recorremos cada categorÃ­a encontrada\n",
    "for nombre_cat, url_cat in categorias.items():\n",
    "    page = 1  # Empezamos por la primera pÃ¡gina de la categorÃ­a\n",
    "    while True:\n",
    "        # Armamos la URL de la pÃ¡gina actual de la categorÃ­a\n",
    "        if page == 1:\n",
    "            url_pagina = url_cat\n",
    "        else:\n",
    "            url_pagina = url_cat.replace('index.html', f'page-{page}.html')\n",
    "\n",
    "        # Hacemos la peticiÃ³n GET a la pÃ¡gina de la categorÃ­a\n",
    "        resp_cat = get_with_retries(url_pagina, timeout=1)\n",
    "        if resp_cat is None:\n",
    "            break\n",
    "        soup_cat = BeautifulSoup(resp_cat.text, 'html.parser')\n",
    "\n",
    "        # Buscamos todos los libros en la pÃ¡gina actual\n",
    "        libros = soup_cat.find_all('article', class_='product_pod')\n",
    "\n",
    "        # Si no hay libros, significa que no hay mÃ¡s pÃ¡ginas en esta categorÃ­a\n",
    "        if not libros:\n",
    "            break\n",
    "\n",
    "        # Recorremos cada libro encontrado en la pÃ¡gina\n",
    "        \n",
    "        for libro in libros:\n",
    "            # Extraemos el tÃ­tulo del libro\n",
    "            titulo = libro.h3.a['title']\n",
    "            # Extraemos el precio\n",
    "            precio = libro.find('p', class_='price_color').text\n",
    "            # Extraemos la disponibilidad (stock)\n",
    "            disponibilidad = libro.find('p', class_='instock availability').text.strip()\n",
    "            # Extraemos el rating (estrellas) como texto (ej: 'Three')\n",
    "            rating = libro.p['class'][1] if len(libro.p['class']) > 1 else 'None'\n",
    "            # Obtenemos el enlace relativo al detalle del libro\n",
    "            enlace_rel = libro.h3.a['href']\n",
    "            # Convertimos el enlace relativo a absoluto\n",
    "            if not enlace_rel.startswith('http'):\n",
    "                if enlace_rel.startswith('../'):\n",
    "                    enlace_rel = enlace_rel.replace('../', '')\n",
    "                enlace_abs = url + 'catalogue/' + enlace_rel\n",
    "            else:\n",
    "                enlace_abs = enlace_rel\n",
    "\n",
    "            # Hacemos una peticiÃ³n GET al detalle del libro para obtener mÃ¡s informaciÃ³n\n",
    "            detalle = get_with_retries(enlace_abs, timeout=1)\n",
    "            if detalle is None:\n",
    "                continue\n",
    "            soup_detalle = BeautifulSoup(detalle.text, 'html.parser')\n",
    "\n",
    "            # Intentamos extraer la categorÃ­a desde el breadcrumb del detalle (por si difiere del nombre_cat)\n",
    "            try:\n",
    "                categoria = soup_detalle.find('ul', class_='breadcrumb').find_all('a')[-1].text.strip()\n",
    "            except: \n",
    "                categoria = nombre_cat\n",
    "\n",
    "            # Intentamos extraer el stock desde el detalle (por si hay mÃ¡s info)\n",
    "            try:\n",
    "                stock = soup_detalle.find('p', class_='instock availability').text.strip()\n",
    "            except:\n",
    "                stock = ''\n",
    "\n",
    "            # --- Google Books API para autores ---\n",
    "            # Formatear el tÃ­tulo para la bÃºsqueda (espacios por %)\n",
    "            titulo_api = titulo.replace(\" \", \"%\")\n",
    "            api_url = f\"https://www.googleapis.com/books/v1/volumes?q=intitle:{titulo_api}\"\n",
    "            autores = []\n",
    "            try:\n",
    "                resp_api = requests.get(api_url, timeout=10)\n",
    "                data_api = resp_api.json()\n",
    "                # Tomar los autores del primer resultado si existe\n",
    "                \n",
    "                if \"items\" in data_api and len(data_api[\"items\"]) > 0:\n",
    "                    autores = data_api[\"items\"][0][\"volumeInfo\"].get(\"authors\", [])\n",
    "                else:\n",
    "                    autores = []\n",
    "            except Exception as e:\n",
    "                autores = []\n",
    "\n",
    "            libro_info = {\n",
    "                'TÃ­tulo': titulo,\n",
    "                'Autores': autores,\n",
    "                'Precio': precio,\n",
    "                'Disponibilidad': disponibilidad,\n",
    "                'Rating': rating,\n",
    "                'CategorÃ­a': categoria,\n",
    "                'Stock': stock,\n",
    "                'URL': enlace_abs\n",
    "            }\n",
    "\n",
    "            # Agregamos el diccionario a la lista de libros\n",
    "            libros_data.append(libro_info)\n",
    "\n",
    "            # Imprimimos la informaciÃ³n del libro en la terminal\n",
    "            \n",
    "\n",
    "            # Pausamos un poco para no saturar el servidor\n",
    "            time.sleep(0.2)\n",
    "        contador +=1\n",
    "        print(contador, libro_info)\n",
    "        # Pasamos a la siguiente pÃ¡gina de la categorÃ­a\n",
    "        page += 1\n",
    "\n",
    "# # Guardamos todos los libros recolectados en un archivo CSV\n",
    "# with open('libros_books_to_scrape.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "#     writer = csv.DictWriter(f, fieldnames=libros_data[0].keys())\n",
    "#     writer.writeheader()\n",
    "#     writer.writerows(libros_data)\n",
    "\n",
    "# print(f\"Total de libros guardados: {len(libros_data)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed72ff",
   "metadata": {},
   "source": [
    "## Codigo funcional de scraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1998bd4",
   "metadata": {},
   "source": [
    "## DIAGRAMAS UML DE LA BASE DE DATOS \n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚         CategorÃ­a           â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ + id : INT (PK)             â”‚\n",
    "â”‚ + nombre : VARCHAR(100)     â”‚\n",
    "â”‚ + url : TEXT                â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                â”‚ (1:N)\n",
    "                â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           Libro             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ + id : INT (PK)             â”‚\n",
    "â”‚ + titulo : VARCHAR(255)     â”‚\n",
    "â”‚ + precio : DECIMAL(10,2)    â”‚\n",
    "â”‚ + disponibilidad : VARCHAR  â”‚\n",
    "â”‚ + rating : INT              â”‚\n",
    "â”‚ + stock : INT               â”‚\n",
    "â”‚ + url : TEXT                â”‚\n",
    "â”‚ + descripcion : TEXT        â”‚      â”‚\n",
    "â”‚ + categoria_id : INT (FK)   â”‚â”€â”€â”\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "                â”‚ (N:M)           â”‚\n",
    "                â”‚                 â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
    "â”‚          Libro_Autor        â”‚   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚\n",
    "â”‚ + libro_id : INT (FK)       â”‚â—„â”€â”€â”˜\n",
    "â”‚ + autor_id : INT (FK)       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                â”‚ (1:N)\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           Autor             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ + id : INT (PK)             â”‚\n",
    "â”‚ + nombre : VARCHAR(150)     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "## N:M que se puede representar a futuro en el proyecto\n",
    "\n",
    "[CategorÃ­a] 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€< N [Libro] >â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€< N â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1 [Autor]\n",
    "                            â”‚\n",
    "                            â”‚ (Tabla intermedia)\n",
    "                            â–¼\n",
    "                      [Libro_Autor]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d4cbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Resumen de datos limpios:\n",
      "       precio_limpio  rating_numerico  stock_numerico\n",
      "count     996.000000       996.000000      996.000000\n",
      "mean       35.134709         2.919679        8.571285\n",
      "std        14.433124         1.436626        5.647425\n",
      "min        10.000000         1.000000        1.000000\n",
      "25%        22.125000         2.000000        3.000000\n",
      "50%        36.110000         3.000000        7.000000\n",
      "75%        47.535000         4.000000       14.000000\n",
      "max        59.990000         5.000000       22.000000\n",
      "ğŸ“ˆ CategorÃ­as mÃ¡s populares:\n",
      "CategorÃ­a\n",
      "Default           152\n",
      "Nonfiction        109\n",
      "Sequential Art     75\n",
      "Add a comment      67\n",
      "Fiction            65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ğŸ’° DistribuciÃ³n de precios:\n",
      "count    996.000000\n",
      "mean      35.134709\n",
      "std       14.433124\n",
      "min       10.000000\n",
      "25%       22.125000\n",
      "50%       36.110000\n",
      "75%       47.535000\n",
      "max       59.990000\n",
      "Name: precio_limpio, dtype: float64\n",
      "\n",
      "â­ DistribuciÃ³n de ratings:\n",
      "rating_numerico\n",
      "1    226\n",
      "2    196\n",
      "3    202\n",
      "4    176\n",
      "5    196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ğŸš¨ Libros sin precio:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# DespuÃ©s de tu scraping\n",
    "df_libros = pd.DataFrame(libros_data)\n",
    "\n",
    "# ğŸ§¹ LIMPIEZA DE DATOS\n",
    "# Limpiar precios: 'Â£19.99' â†’ 19.99\n",
    "df_libros['precio_limpio'] = (\n",
    "    df_libros['Precio']\n",
    "    .str.replace(r'[^\\d\\.]', '', regex=True)\n",
    "    .astype(float))\n",
    "\n",
    "# Convertir ratings: 'Three' â†’ 3\n",
    "rating_map = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "df_libros['rating_numerico'] = df_libros['Rating'].map(rating_map).fillna(0)\n",
    "\n",
    "# Limpiar stock: 'In stock (22 available)' â†’ 22\n",
    "df_libros['stock_numerico'] = df_libros['Stock'].str.extract(r'(\\d+)').astype(int).fillna(0)\n",
    "\n",
    "# Ver quÃ© tan sucios estÃ¡n tus datos\n",
    "print(\"ğŸ“Š Resumen de datos limpios:\")\n",
    "print(df_libros[['precio_limpio', 'rating_numerico', 'stock_numerico']].describe())\n",
    "\n",
    "# Convertir de vuelta a lista de diccionarios para MySQL\n",
    "libros_data_limpios = df_libros.to_dict('records')\n",
    "\n",
    "# Breves analisis\n",
    "# ğŸ” EXPLORACIÃ“N RÃPIDA\n",
    "print(\"ğŸ“ˆ CategorÃ­as mÃ¡s populares:\")\n",
    "print(df_libros['CategorÃ­a'].value_counts().head())\n",
    "\n",
    "print(\"\\nğŸ’° DistribuciÃ³n de precios:\")\n",
    "print(df_libros['precio_limpio'].describe())\n",
    "\n",
    "print(\"\\nâ­ DistribuciÃ³n de ratings:\")\n",
    "print(df_libros['rating_numerico'].value_counts().sort_index())\n",
    "\n",
    "# Detectar problemas\n",
    "print(\"\\nğŸš¨ Libros sin precio:\")\n",
    "print(df_libros[df_libros['precio_limpio'].isna()].shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf373a97",
   "metadata": {},
   "source": [
    "## Modo de hacer con MYSLQ (mysql-connector-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0076ff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ConexiÃ³n exitosa a MySQL (Docker)\n",
      "âœ… Tablas creadas exitosamente\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "def conectar_mysql():\n",
    "    \"\"\"Crear conexiÃ³n a MySQL\"\"\"\n",
    "    try:\n",
    "        conexion = mysql.connector.connect(\n",
    "            host='localhost',       \n",
    "            user='root',            # Usuario por defecto en tu contenedor\n",
    "            password='12345',       # ContraseÃ±a\n",
    "            database='libreria_books' # Base creada en Docker\n",
    "        )\n",
    "        \n",
    "        if conexion.is_connected():\n",
    "            print(\"âœ… ConexiÃ³n exitosa a MySQL (Docker)\")\n",
    "            return conexion\n",
    "            \n",
    "    except Error as e:\n",
    "        print(f\"âŒ Error conectando a MySQL: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def crear_tablas_mysql(conexion):\n",
    "    \"\"\"Crear tablas usando SQL puro\"\"\"\n",
    "    cursor = conexion.cursor()\n",
    "    \n",
    "    # Crear tabla categorias\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS categorias (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            nombre VARCHAR(100) NOT NULL UNIQUE,\n",
    "            descripcion TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    # Crear tabla libros\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS libros (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            titulo VARCHAR(100) NOT NULL,\n",
    "            precio DECIMAL(10,2),\n",
    "            rating INT,\n",
    "            stock INT DEFAULT 0,\n",
    "            url TEXT,\n",
    "            categoria_id INT,\n",
    "            FOREIGN KEY (categoria_id) REFERENCES categorias(id)\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    # Crear tabla autores\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS autores (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            nombre VARCHAR(255) NOT NULL,\n",
    "            biografia TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    #Tabla relaciÃ³n muchos a muchos\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS libro_autor (\n",
    "            libro_id INT,\n",
    "            autor_id INT,\n",
    "            PRIMARY KEY (libro_id, autor_id),\n",
    "            FOREIGN KEY (libro_id) REFERENCES libros(id) ON DELETE CASCADE,\n",
    "            FOREIGN KEY (autor_id) REFERENCES autores(id) ON DELETE CASCADE\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    conexion.commit()\n",
    "    print(\"âœ… Tablas creadas exitosamente\")\n",
    "\n",
    "def insertar_datos_mysql(conexion, libros_data):\n",
    "    \"\"\"Insertar datos usando mysql-connector-python\"\"\"\n",
    "    cursor = conexion.cursor()\n",
    "    \n",
    "    try:\n",
    "        # Insertar categorÃ­as Ãºnicas\n",
    "        categorias_unicas = list(set([libro['CategorÃ­a'] for libro in libros_data]))\n",
    "        \n",
    "        for categoria in categorias_unicas:\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT IGNORE INTO categorias (nombre) \n",
    "                VALUES (%s)\n",
    "            \"\"\", (categoria,))\n",
    "        \n",
    "        # Insertar libros\n",
    "        for libro in libros_data:\n",
    "            # Primero obtener categoria_id\n",
    "            cursor.execute(\"SELECT id FROM categorias WHERE nombre = %s\", (libro['CategorÃ­a'],))\n",
    "            categoria_id = cursor.fetchone()[0]\n",
    "            \n",
    "            # Insertar libro\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO libros (titulo, precio, rating, stock, url, categoria_id)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "            \"\"\", (\n",
    "                libro['titulo'],\n",
    "                libro.get('precio', 0),\n",
    "                libro.get('rating', 0), \n",
    "                libro.get('stock', 0),\n",
    "                libro.get('url', ''),\n",
    "                categoria_id\n",
    "            ))\n",
    "            \n",
    "            libro_id = cursor.lastrowid\n",
    "            \n",
    "            # Insertar autor (si existe) (lista)\n",
    "            if libro.get('Autores') and isinstance(libro['Autores'], list):\n",
    "                for autor_nombre in libro['Autores']:\n",
    "                    # Insertar autor si no existe\n",
    "                    cursor.execute(\"\"\"\n",
    "                        INSERT IGNORE INTO autores (nombre)\n",
    "                        VALUES (%s)\n",
    "                    \"\"\", (autor_nombre,))\n",
    "                    \n",
    "                    # Obtener autor_id\n",
    "                    cursor.execute(\"SELECT id FROM autores WHERE nombre = %s\", (autor_nombre,))\n",
    "                    autor_id = cursor.fetchone()[0]\n",
    "\n",
    "                    # Crear relaciÃ³n libro-autor\n",
    "                    cursor.execute(\"\"\"\n",
    "                        INSERT IGNORE INTO libro_autor (libro_id, autor_id)\n",
    "                        VALUES (%s, %s)\n",
    "                    \"\"\", (libro_id, autor_id))\n",
    "        \n",
    "            conexion.commit()\n",
    "        print(f\"âœ… {len(libros_data)} libros insertados exitosamente\")\n",
    "        \n",
    "    except Error as e:\n",
    "        print(f\"âŒ Error insertando datos: {e}\")\n",
    "        conexion.rollback()\n",
    "\n",
    "# Ejemplo de uso\n",
    "conexion = conectar_mysql()\n",
    "if conexion:\n",
    "    crear_tablas_mysql(conexion)\n",
    "    insertar_datos_mysql(conexion, libros_data)\n",
    "    conexion.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7241fc2",
   "metadata": {},
   "source": [
    "## Modo de hacer con SQL Alchemy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Float, ForeignKey, Text\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship, sessionmaker\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Categoria(Base):\n",
    "    __tablename__ = 'categorias'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    nombre = Column(String(100), unique=True, nullable=False)\n",
    "    descripcion = Column(Text)\n",
    "    \n",
    "    # RelaciÃ³n\n",
    "    libros = relationship(\"Libro\", back_populates=\"categoria\")\n",
    "\n",
    "class Autor(Base):\n",
    "    __tablename__ = 'autores'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    nombre = Column(String(255), nullable=False)\n",
    "    biografia = Column(Text)\n",
    "\n",
    "class Libro(Base):\n",
    "    __tablename__ = 'libros'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    titulo = Column(String(500), nullable=False)\n",
    "    precio = Column(Float)\n",
    "    rating = Column(Integer)  # 1-5\n",
    "    stock = Column(Integer, default=0)\n",
    "    url = Column(Text)\n",
    "    categoria_id = Column(Integer, ForeignKey('categorias.id'))\n",
    "    \n",
    "    # Relaciones\n",
    "    categoria = relationship(\"Categoria\", back_populates=\"libros\")\n",
    "    autores = relationship(\"Autor\", secondary=\"libro_autor\", back_populates=\"libros\")\n",
    "\n",
    "# Tabla de relaciÃ³n muchos a muchos\n",
    "from sqlalchemy import Table\n",
    "libro_autor = Table('libro_autor', Base.metadata,\n",
    "    Column('libro_id', Integer, ForeignKey('libros.id')),\n",
    "    Column('autor_id', Integer, ForeignKey('autores.id'))\n",
    ")\n",
    "\n",
    "# Configurar la relaciÃ³n en Autor\n",
    "Autor.libros = relationship(\"Libro\", secondary=libro_autor, back_populates=\"autores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf5e1a4",
   "metadata": {},
   "source": [
    "### Consultas mas lindas con (ipython-sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28667fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219fd0ad",
   "metadata": {},
   "source": [
    "### Graficos Opcional con (matplotlib)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
