{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0cb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1. Obtener la URL\n",
    "url = \"https://books.toscrape.com/\"\n",
    "respuesta_obtenida = requests.get(url)\n",
    "html_obtenido = respuesta_obtenida.text  # HTML como string\n",
    "\n",
    "# 2. Parsear ese HTML con BeautifulSoup\n",
    "soup = BeautifulSoup(html_obtenido, 'html.parser')  # <- 춰ESTO FALTABA!\n",
    "\n",
    "# 3. Buscar el primer t칤tulo <h3>\n",
    "primer_h3 = soup.find('h3')\n",
    "\n",
    "# 4. Mostrar el contenido\n",
    "print(primer_h3)         # Muestra todo el tag <h3>...</h3>\n",
    "print(primer_h3.text)    # Muestra solo el texto (t칤tulo del libro)\n",
    "print(soup.h3.text)      # Equivalente\n",
    "\n",
    "# 5. Trayendo todos los <h3>\n",
    "\n",
    "h3_todos = soup.find_all('h3')\n",
    "print(h3_todos) #lista con todos los elementos de h3\n",
    "\n",
    "# 6. Iteracion de todos los elementos poniendo solo texto \n",
    "contador = 0\n",
    "for unoporuno in h3_todos:\n",
    "    contador+=1\n",
    "\n",
    "    print(contador, unoporuno.text)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96f3bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游늯 P치gina 1 -> 20 libros encontrados\n",
      "a-light-in-the-attic_1000/index.html\n",
      "tipping-the-velvet_999/index.html\n",
      "soumission_998/index.html\n",
      "sharp-objects_997/index.html\n",
      "sapiens-a-brief-history-of-humankind_996/index.html\n",
      "the-requiem-red_995/index.html\n",
      "the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "the-black-maria_991/index.html\n",
      "starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "shakespeares-sonnets_989/index.html\n",
      "set-me-free_988/index.html\n",
      "scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "rip-it-up-and-start-again_986/index.html\n",
      "our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "olio_984/index.html\n",
      "mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "libertarianism-for-beginners_982/index.html\n",
      "its-only-the-himalayas_981/index.html\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "libros = None\n",
    "\n",
    "\n",
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "\n",
    "#funcion para recorrer todas las paginas \n",
    "\n",
    "for page in range(1, 2):  # Hay 50 p치ginas en total\n",
    "    url = base_url.format(page)\n",
    "    respuesta = requests.get(url)\n",
    "    soup = BeautifulSoup(respuesta.text, 'html.parser')\n",
    "\n",
    "    # Aqu칤 haces scraping de los libros de esa p치gina\n",
    "    libros = soup.find_all('article', class_='product_pod')\n",
    "    print(f\"游늯 P치gina {page} -> {len(libros)} libros encontrados\")\n",
    "\n",
    "# recorrer_paginas()\n",
    "\n",
    "\n",
    "#   \n",
    "\n",
    "for libro in libros:\n",
    "    titulo = libro.h3.a['title']\n",
    "    precio = libro.find('p', class_='price_color').text\n",
    "    disponibilidad = libro.find('p', class_='instock availability').text.strip()\n",
    "\n",
    "    # Enlace al detalle del libro (relativo -> convertir a absoluto)\n",
    "    enlace_relativo = libro.h3.a['href']\n",
    "    print(enlace_relativo)\n",
    "    enlace_absoluto = \"https://books.toscrape.com/catalogue/\" + enlace_relativo\n",
    "\n",
    "    #print(f\"游닄 {titulo} | 游눳 {precio} | 游닍 {disponibilidad} | 游댕 {enlace_absoluto}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "detalle = requests.get(enlace_absoluto)\n",
    "soup_detalle = BeautifulSoup(detalle.text, 'html.parser')\n",
    "\n",
    "# Categor칤a: est치 en un breadcrumb (<ul class=\"breadcrumb\">)\n",
    "categoria = soup_detalle.find('ul', class_='breadcrumb').find_all('a')[-1].text\n",
    "\n",
    "#print(f\"游닄 {titulo} | 游눳 {precio} | 游닍 {disponibilidad} | 游늭 {categoria}\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f384c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categor칤as encontradas: 50\n",
      "1 {'T칤tulo': \"It's Only the Himalayas\", 'Autores': ['S. Bedford'], 'Precio': '츽춲45.17', 'Disponibilidad': 'In stock', 'Rating': 'Two', 'Categor칤a': 'Travel', 'Stock': 'In stock (19 available)', 'URL': 'https://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html'}\n",
      "2 {'T칤tulo': 'Full Moon over Noah칙\\x80\\x99s Ark: An Odyssey to Mount Ararat and Beyond', 'Autores': ['Rick Antonson'], 'Precio': '츽춲49.43', 'Disponibilidad': 'In stock', 'Rating': 'Four', 'Categor칤a': 'Travel', 'Stock': 'In stock (15 available)', 'URL': 'https://books.toscrape.com/catalogue/full-moon-over-noahs-ark-an-odyssey-to-mount-ararat-and-beyond_811/index.html'}\n",
      "3 {'T칤tulo': 'See America: A Celebration of Our National Parks & Treasured Sites', 'Autores': ['Creative Action Network'], 'Precio': '츽춲48.87', 'Disponibilidad': 'In stock', 'Rating': 'Three', 'Categor칤a': 'Travel', 'Stock': 'In stock (14 available)', 'URL': 'https://books.toscrape.com/catalogue/see-america-a-celebration-of-our-national-parks-treasured-sites_732/index.html'}\n",
      "4 {'T칤tulo': 'Vagabonding: An Uncommon Guide to the Art of Long-Term World Travel', 'Autores': ['Shortcut Edition'], 'Precio': '츽춲36.94', 'Disponibilidad': 'In stock', 'Rating': 'Two', 'Categor칤a': 'Travel', 'Stock': 'In stock (8 available)', 'URL': 'https://books.toscrape.com/catalogue/vagabonding-an-uncommon-guide-to-the-art-of-long-term-world-travel_552/index.html'}\n",
      "5 {'T칤tulo': 'Under the Tuscan Sun', 'Autores': ['Frances Mayes'], 'Precio': '츽춲37.33', 'Disponibilidad': 'In stock', 'Rating': 'Three', 'Categor칤a': 'Travel', 'Stock': 'In stock (7 available)', 'URL': 'https://books.toscrape.com/catalogue/under-the-tuscan-sun_504/index.html'}\n",
      "6 {'T칤tulo': 'A Summer In Europe', 'Autores': ['Marilyn Brant'], 'Precio': '츽춲44.34', 'Disponibilidad': 'In stock', 'Rating': 'Two', 'Categor칤a': 'Travel', 'Stock': 'In stock (7 available)', 'URL': 'https://books.toscrape.com/catalogue/a-summer-in-europe_458/index.html'}\n",
      "7 {'T칤tulo': 'The Great Railway Bazaar', 'Autores': ['Paul Theroux'], 'Precio': '츽춲30.54', 'Disponibilidad': 'In stock', 'Rating': 'One', 'Categor칤a': 'Travel', 'Stock': 'In stock (6 available)', 'URL': 'https://books.toscrape.com/catalogue/the-great-railway-bazaar_446/index.html'}\n",
      "8 {'T칤tulo': 'A Year in Provence (Provence #1)', 'Autores': ['Peter Mayle'], 'Precio': '츽춲56.88', 'Disponibilidad': 'In stock', 'Rating': 'Four', 'Categor칤a': 'Travel', 'Stock': 'In stock (6 available)', 'URL': 'https://books.toscrape.com/catalogue/a-year-in-provence-provence-1_421/index.html'}\n",
      "9 {'T칤tulo': 'The Road to Little Dribbling: Adventures of an American in Britain (Notes From a Small Island #2)', 'Autores': ['Bill Bryson'], 'Precio': '츽춲23.21', 'Disponibilidad': 'In stock', 'Rating': 'One', 'Categor칤a': 'Travel', 'Stock': 'In stock (3 available)', 'URL': 'https://books.toscrape.com/catalogue/the-road-to-little-dribbling-adventures-of-an-american-in-britain-notes-from-a-small-island-2_277/index.html'}\n",
      "10 {'T칤tulo': 'Neither Here nor There: Travels in Europe', 'Autores': ['Bill Bryson'], 'Precio': '츽춲38.95', 'Disponibilidad': 'In stock', 'Rating': 'Three', 'Categor칤a': 'Travel', 'Stock': 'In stock (3 available)', 'URL': 'https://books.toscrape.com/catalogue/neither-here-nor-there-travels-in-europe_198/index.html'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 131\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    130\u001b[39m     start_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     data = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m     end_time = time.time()\n\u001b[32m    133\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTiempo total de ejecuci칩n: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m segundos\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 113\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    110\u001b[39m futures = [executor.submit(process_book, libro, nombre_cat) \u001b[38;5;28;01mfor\u001b[39;00m libro \u001b[38;5;129;01min\u001b[39;00m libros]\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     libro_info = \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m libro_info:\n\u001b[32m    115\u001b[39m         libros_data.append(libro_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def get_with_retries(url, headers=None, max_retries=3, timeout=5):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=timeout)\n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f'Intento {attempt+1} fallido para {url}: {e}')\n",
    "            time.sleep(2)\n",
    "    print(f'No se pudo acceder a {url} despu칠s de {max_retries} intentos.')\n",
    "    return None\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "base_url = \"https://books.toscrape.com/\"\n",
    "\n",
    "def get_google_books_authors(titulo):\n",
    "    titulo_api = titulo.replace(\" \", \"%\")\n",
    "    api_url = f\"https://www.googleapis.com/books/v1/volumes?q=intitle:{titulo_api}\"\n",
    "    try:\n",
    "        resp_api = requests.get(api_url, timeout=10)\n",
    "        data_api = resp_api.json()\n",
    "        if \"items\" in data_api and len(data_api[\"items\"]) > 0:\n",
    "            return data_api[\"items\"][0][\"volumeInfo\"].get(\"authors\", [])\n",
    "    except:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def process_book(libro, nombre_cat):\n",
    "    titulo = libro.h3.a['title']\n",
    "    precio = libro.find('p', class_='price_color').text\n",
    "    disponibilidad = libro.find('p', class_='instock availability').text.strip()\n",
    "    rating = libro.p['class'][1] if len(libro.p['class']) > 1 else 'None'\n",
    "    \n",
    "    enlace_rel = libro.h3.a['href']\n",
    "    if enlace_rel.startswith('../'):\n",
    "        enlace_rel = enlace_rel.replace('../', '')\n",
    "    enlace_abs = base_url + 'catalogue/' + enlace_rel\n",
    "    \n",
    "    # Obtener detalles de la p치gina del libro\n",
    "    detalle = get_with_retries(enlace_abs, headers=headers)\n",
    "    if detalle is None:\n",
    "        return None\n",
    "    \n",
    "    soup_detalle = BeautifulSoup(detalle.text, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        categoria = soup_detalle.find('ul', class_='breadcrumb').find_all('a')[-1].text.strip()\n",
    "    except:\n",
    "        categoria = nombre_cat\n",
    "    \n",
    "    try:\n",
    "        stock = soup_detalle.find('p', class_='instock availability').text.strip()\n",
    "    except:\n",
    "        stock = ''\n",
    "    \n",
    "    # Obtener autores de Google Books (en paralelo)\n",
    "    autores = get_google_books_authors(titulo)\n",
    "    \n",
    "    return {\n",
    "        'T칤tulo': titulo,\n",
    "        'Autores': autores,\n",
    "        'Precio': precio,\n",
    "        'Disponibilidad': disponibilidad,\n",
    "        'Rating': rating,\n",
    "        'Categor칤a': categoria,\n",
    "        'Stock': stock,\n",
    "        'URL': enlace_abs\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Obtener categor칤as\n",
    "    respuesta = get_with_retries(base_url, headers=headers)\n",
    "    if respuesta is None:\n",
    "        raise Exception('No se pudo obtener la p치gina principal')\n",
    "    \n",
    "    soup = BeautifulSoup(respuesta.text, 'html.parser')\n",
    "    categorias = {\n",
    "        a.text.strip(): base_url + a['href'] \n",
    "        for a in soup.select('ul.nav.nav-list li a') \n",
    "        if a['href'] != 'catalogue/category/books_1/index.html'\n",
    "    }\n",
    "    \n",
    "    print(f\"Categor칤as encontradas: {len(categorias)}\")\n",
    "    \n",
    "    libros_data = []\n",
    "    contador = 0\n",
    "    \n",
    "    for nombre_cat, url_cat in categorias.items():\n",
    "        page = 1\n",
    "        while True:\n",
    "            url_pagina = url_cat if page == 1 else url_cat.replace('index.html', f'page-{page}.html')\n",
    "            \n",
    "            resp_cat = get_with_retries(url_pagina, headers=headers)\n",
    "            if resp_cat is None:\n",
    "                break\n",
    "                \n",
    "            soup_cat = BeautifulSoup(resp_cat.text, 'html.parser')\n",
    "            libros = soup_cat.find_all('article', class_='product_pod')\n",
    "            \n",
    "            if not libros:\n",
    "                break\n",
    "            \n",
    "            # Procesar libros en paralelo (limitado a 3 hilos para no saturar)\n",
    "            with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "                futures = [executor.submit(process_book, libro, nombre_cat) for libro in libros]\n",
    "                \n",
    "                for future in futures:\n",
    "                    libro_info = future.result()\n",
    "                    if libro_info:\n",
    "                        libros_data.append(libro_info)\n",
    "                        contador += 1\n",
    "                        print(contador, libro_info)\n",
    "            \n",
    "            # Verificar si hay siguiente p치gina\n",
    "            next_page = soup_cat.find('li', class_='next')\n",
    "            if not next_page:\n",
    "                break\n",
    "                \n",
    "            page += 1\n",
    "            time.sleep(0.5)  # Peque침a pausa entre p치ginas\n",
    "    \n",
    "    return libros_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    data = main()\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nTiempo total de ejecuci칩n: {end_time - start_time:.2f} segundos\")\n",
    "    print(f\"Total de libros obtenidos: {len(data)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
