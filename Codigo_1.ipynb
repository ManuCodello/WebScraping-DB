{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0cb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1. Obtener la URL\n",
    "url = \"https://books.toscrape.com/\"\n",
    "respuesta_obtenida = requests.get(url)\n",
    "html_obtenido = respuesta_obtenida.text  # HTML como string\n",
    "\n",
    "# 2. Parsear ese HTML con BeautifulSoup\n",
    "soup = BeautifulSoup(html_obtenido, 'html.parser')  # <- Â¡ESTO FALTABA!\n",
    "\n",
    "# 3. Buscar el primer tÃ­tulo <h3>\n",
    "primer_h3 = soup.find('h3')\n",
    "\n",
    "# 4. Mostrar el contenido\n",
    "print(primer_h3)         # Muestra todo el tag <h3>...</h3>\n",
    "print(primer_h3.text)    # Muestra solo el texto (tÃ­tulo del libro)\n",
    "print(soup.h3.text)      # Equivalente\n",
    "\n",
    "# 5. Trayendo todos los <h3>\n",
    "\n",
    "h3_todos = soup.find_all('h3')\n",
    "print(h3_todos) #lista con todos los elementos de h3\n",
    "\n",
    "# 6. Iteracion de todos los elementos poniendo solo texto \n",
    "contador = 0\n",
    "for unoporuno in h3_todos:\n",
    "    contador+=1\n",
    "\n",
    "    print(contador, unoporuno.text)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96f3bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ PÃ¡gina 1 -> 20 libros encontrados\n",
      "a-light-in-the-attic_1000/index.html\n",
      "tipping-the-velvet_999/index.html\n",
      "soumission_998/index.html\n",
      "sharp-objects_997/index.html\n",
      "sapiens-a-brief-history-of-humankind_996/index.html\n",
      "the-requiem-red_995/index.html\n",
      "the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "the-black-maria_991/index.html\n",
      "starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "shakespeares-sonnets_989/index.html\n",
      "set-me-free_988/index.html\n",
      "scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "rip-it-up-and-start-again_986/index.html\n",
      "our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "olio_984/index.html\n",
      "mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "libertarianism-for-beginners_982/index.html\n",
      "its-only-the-himalayas_981/index.html\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "libros = None\n",
    "\n",
    "\n",
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "\n",
    "#funcion para recorrer todas las paginas \n",
    "\n",
    "for page in range(1, 2):  # Hay 50 pÃ¡ginas en total\n",
    "    url = base_url.format(page)\n",
    "    respuesta = requests.get(url)\n",
    "    soup = BeautifulSoup(respuesta.text, 'html.parser')\n",
    "\n",
    "    # AquÃ­ haces scraping de los libros de esa pÃ¡gina\n",
    "    libros = soup.find_all('article', class_='product_pod')\n",
    "    print(f\"ðŸ“„ PÃ¡gina {page} -> {len(libros)} libros encontrados\")\n",
    "\n",
    "# recorrer_paginas()\n",
    "\n",
    "\n",
    "#   \n",
    "\n",
    "for libro in libros:\n",
    "    titulo = libro.h3.a['title']\n",
    "    precio = libro.find('p', class_='price_color').text\n",
    "    disponibilidad = libro.find('p', class_='instock availability').text.strip()\n",
    "\n",
    "    # Enlace al detalle del libro (relativo -> convertir a absoluto)\n",
    "    enlace_relativo = libro.h3.a['href']\n",
    "    print(enlace_relativo)\n",
    "    enlace_absoluto = \"https://books.toscrape.com/catalogue/\" + enlace_relativo\n",
    "\n",
    "    #print(f\"ðŸ“š {titulo} | ðŸ’µ {precio} | ðŸ“¦ {disponibilidad} | ðŸ”— {enlace_absoluto}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "detalle = requests.get(enlace_absoluto)\n",
    "soup_detalle = BeautifulSoup(detalle.text, 'html.parser')\n",
    "\n",
    "# CategorÃ­a: estÃ¡ en un breadcrumb (<ul class=\"breadcrumb\">)\n",
    "categoria = soup_detalle.find('ul', class_='breadcrumb').find_all('a')[-1].text\n",
    "\n",
    "#print(f\"ðŸ“š {titulo} | ðŸ’µ {precio} | ðŸ“¦ {disponibilidad} | ðŸ“‚ {categoria}\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f384c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
